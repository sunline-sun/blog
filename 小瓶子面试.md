## mysql
### inndb数据存储结构-b+树
- B+树是一个N叉树的树形结构，一个节点下可以有N个节点，N的大小取决于数据块的大小，也就是innodb中的页。B+树只有最后一层会存储行里的所有数据，其他层只存ID，并且底层是个链表结构，可以方便范围查询。以整形字段为例，一个页可以存储1200个数据，4层也就是可以存储1200的3次方的数据，当然因为最后一层除了存储ID还存储了整行的数据，但是一个4层架构也可以存几亿的数据


### 为什么用b+树不用b树
- 哈希表不可以，因为有哈希冲突，并且占用内存，并且不适合范围查询，适用于等值查询场景，如memcached以及其他一些nosql引擎，但是mysql memory存储引擎用的hash索引
- 数组链表不可以，因为数组插入慢，链表查询慢，适用于静态存储
- 二叉树不可以，因为每个节点存储数据少，分支少，导致树的深度过高，复杂度变高
- B树不可以，因为B树节点除了key值还会存数据，导致每个磁盘块数据量少，导致树深度变高，增加io次数
- B+树可以，因为B+树只有末级叶子节点存储数据，其他只存key，树深度很低，而且末级叶子节点是个链表结构，所以支持两种查询方式，树查询和链表查询

### 如何提升sql查询性能 
- group by优化
  - 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null
  - 尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort
  - 如果 group by 需要统计的数据量不大，尽量只使用内存临时表
  - 也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表
  - 如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果
- join优化
  - 这种关联查询尽量先把每个关联的表过滤成小表，减少关联次数
  - join建议使用BKA算法，使用方式就是给被驱动表关联字段加上索引
  - join的时候最好小表放在前面当做驱动表
- 对索引字段最好不要做函数操作，因为可能会破坏索引的有序性，优化器可能会放弃走索引
- 对索引字段最好不要有类型转换，也会导致不走索引
- 最好不要使用select '*' from ,而是查询具体的列
- 尽量使用到覆盖索引，避免回表查询
- 使用betwwen and代替in
- 创建合适的索引
- like的时候最好不要左边也like，如like（%1%）


### 慢查询分析与优化-explain，可以了解详细点
- 导致慢查询的原因
  - 索引没有设计好
  - mysql选错了索引（因为mysql优化器的逻辑：扫描行数、是否回写、是否用临时表、是否排序等，出现选错索引就是因为判断扫描行数的时候统计错了（删除历史数据后再插入）和判断需要回写了，比如select * from t where a between 5000 and 10000,会选全表查询），这时候可以用force index强制走索引，或者analze table t重新统计信息
- explain，执行计划，可以通过这个判断sql的执行情况
  - id，sql执行的顺序，ID越大越先执行，如果id一致，按照从上到下的顺序执行的
  - select type，就是查询类型，包括
    - simple，最简单的查询，不包含子查询和union
    - primary，对于有子查询的最外层的select就是primary类型
    - union，union语句中后面的查询
    - DEPENDENT UNION，一般是子查询中第二个查询
    - UNION RESULT，union的结果
    - SUBQUERY，子查询第一个select
  - table，表示查询的是哪个表的，有时候也会是虚拟表，虚拟表最后一位是数字，代表id是多少的查询
  - type，表示是否用了索引，重点优化字段
    - system，const的特殊情况。比如select * from (select id from a where b = 1),里面子查询只有一条数据，外面的就是system类型 
    - const，表示只有一个匹配行，通过索引一次就能找到，一般就是主键或者唯一索引的查询
    - eq_reg，表示表中只有一条记录与之匹配，一般是关联查询的时候，关联条件的字段是主键或者唯一索引
    - ref，就是普通索引的查询
    - range，检索给定范围的查询，一般就是大于小于between这种查询
    - index，遍历索引树，比ALL快点，因为索引文件没有数据文件大
    - ALL，全表扫描
  - possible_keys，表示可能用到的索引，不一定真实使用了
  - key，实际用到的索引
  - key_len，表示索引使用的字节数，可以计算用到的索引长度
  - ref，表示哪一列被使用了
  - rows，查询大致需要扫描的行数
  - filter，表示选取的行和读取的行的百分比，100表示选取了100%，80表示读取了80%。
  - extra，一些额外的信息，也是优化的时候注意的地方
    - Using filesort，使用外部的索引排序，不是用的表内的索引排序，一般需要优化
    - Using temporary，是否使用了临时表，一般出现在order by 和group by 里，最好优化
    - Using index，表示用到了覆盖索引
    - Using where，使用了where过滤
    - Using join buffer，使用了join 缓存

### 数据库表锁机制
#### 按锁粒度划分
- myisam只支持表锁，innodb支持表锁和行锁
- 全局锁
  - 对整个数据库实例加锁，加锁后整个数据库内的更新等操作都会阻塞。
  - 应用场景是用于全库逻辑备份的时候。
  - 风险就是全局锁下所有业务都停了，主从同步也会延迟
- 表级锁
  - 表锁，粒度较大，会锁住整张表，特点是开销小，锁表块，但是容易出现锁冲突。
  - MDL锁，MDL锁是防止DDL和DML之间冲突的锁，DDL加写锁，DML加读锁，读读不冲突，读写、写写互斥
- 行锁
  - 粒度小，更新操作会对影响到的行加行锁，并且会在事务提交后才释放，可以减少锁冲突，会出现死锁，所以实际用的时候最好把可能会存在锁冲突的表放在后面操作
  - RR隔离级别下，如果条件列是索引列，锁住的是索引记录，没有索引的话会锁整个表
- innodb下锁的算法有3种，next-key lock（就是间隙锁加记录锁）、间隙锁、记录锁，
  - next-key lock是锁的基本单位，但是对于不同情况的查询有优化机制
  - 间隙锁是为了防止幻读
  - 如果是唯一索引下的等值查询，退化为记录锁
  - 如果普通索引下的等值查询，退化为间隙锁
 
#### 按锁类别划分
- 共享锁，查询操作加共享锁
- 排它锁，更新操作加排它锁
- 共享锁下，只可以加共享锁，排它锁下什么锁都不能加，为了保证读写安全

### 什么时候会锁表，如何避免 
- RR隔离级别下，update如果条件列没有索引，会退化为表锁
- 锁表情况下容易造成锁冲突

- 避免方式
 - 尽量避免大事务，避免锁冲突
 - 尽量使用索引，行锁影响比表锁要小
 - 访问表的顺序最好一致，避免死锁

### 大数据量插入，如何避免锁表-可以采用批量插入？

### sql优化器是如何优化的
- 主要作用就是对sql进行优化，比如判断用哪个索引，多表关联的时候，决定每个表的链接顺序
- 优化过程会判断扫描行数、是否回写、是否用临时表、是否排序等多个维度进行判断

### 聚簇索引，索引下推，回表，覆盖索引，最左匹配



## jvm

### 内存模型 
- 线程私有的
   - 程序计数器
   - 虚拟机栈
   - 本地方法栈
- 线程共享的
   - 堆
   - 方法区
   - 直接内存

### jvm垃圾回收算法及使用场景
- 标记清除
- 标记复制 - 新生代
- 标记整理 - 老年代

### 垃圾回收器有哪些（一般用cms和g1）
- 新生代
  - Serial
  - ParNew
  - Parallel Scavenge
- 老年代
  - Serial Old
  - Parallel Old
  - CMS
- 整个堆的
  - G1

### jvm线上配置，如何调优 
- 调优工具
  - jconsole
  - jvisualvm
- 调优参数
  - -Xms2g：初始化推大小为 2g；
  - -Xmx2g：堆最大内存为 2g；
  - -XX:NewRatio=4：设置年轻的和老年代的内存比例为 1:4；
  - -XX:SurvivorRatio=8：设置新生代 Eden 和 Survivor 比例为 8:2；
  - –XX:+UseParNewGC：指定使用 ParNew + Serial Old 垃圾回收器组合；
  - -XX:+UseParallelOldGC：指定使用 ParNew + ParNew Old 垃圾回收器组合
  - -XX:+UseConcMarkSweepGC：指定使用 CMS + Serial Old 垃圾回收器组合；
  - -XX:+PrintGC：开启打印 gc 信息；
  - -XX:+PrintGCDetails：打印 gc 详细信息。


### 线上应用内存溢出后怎么办，dump gc文件后如何分析
- 

## java基础 

### hashmap原理（1.7和1.8）
- 结构
- 构造方法
- 变量：容量、负载因子、阈值
- 查询
- 插入
- 扩容
- https://github.com/sunline-sun/blog/blob/main/java%E9%9B%86%E5%90%88/HashMap.md

### currenthashmap原理 
- 加锁方式（1.7和1.8区别）
- 数据结构
- 并发下初始化
- 怎么保证线程安全的
- 扩容
- 如果保证读和扩容并发
- 对于红黑树来说，读和写可以并行么？
- 插入
- 查询
- https://github.com/sunline-sun/blog/blob/main/java%E9%9B%86%E5%90%88/currentHashMap.md

### jdk并发包 有哪些类，重点讲下，实现原理
- AQS
  - acquire()方法
  - conditionObject内部类
  - 模板模式
  - 两种锁模式（独占、共享）
  - CountDownLatch
  - https://github.com/sunline-sun/blog/blob/main/Java%E5%B9%B6%E5%8F%91/AbstractQueuedSynchronizer.md
- RennTranck
  - lock()
  - unlock()
  - https://github.com/sunline-sun/blog/blob/main/Java%E5%B9%B6%E5%8F%91/ReentrantLock.md
- BlockingQueue
  - ArrayBlockingQueue
  - https://github.com/sunline-sun/blog/blob/main/Java%E5%B9%B6%E5%8F%91/BlockingQueue.md
  - LinkedBlockingQueue
  - SynchronousQueue
  - PriorityBlockingQueue
  - 
- 线程池  
- https://github.com/sunline-sun/blog/blob/main/Java%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E6%B1%A0.md

### syncnizenizd锁升级
- 偏向锁
- 轻量级锁
- 重量级锁

## redis
- https://github.com/sunline-sun/blog/blob/main/redis/%E7%AC%94%E8%AE%B0.md

### redis常见数据结构 
- string
- hash
- list
- set
- zset

### redis5新特性-例如：redis用集群用slot，而不是哨兵机制了?
- Stream数据结构
- 

### redis穿透、雪崩及解决方案
- 布隆过滤器
- 设置null
- 设置过期时间加随机数，保证不再同一时间过期

### redis使用规范 

### redis 大key如何处理 
- memory usage 发现
- 如果可以拆分就拆分
- 如果导致阻塞，可以用lazyfree异步删除，减少阻塞

### 如何实现分布式锁，有哪几种方案，有开源实现吗（有，目前流行的有redission）
- 数据库层（主键id）
- redis
- zookeeper
- redission

## mq

### 目前mq用什么框架-rocketmq
- 可以保证消息的顺序性
- 

### 实现机制（生产者、服务broker、消费者、topic、group...）
- Producer,生产者，Producer由用户进行分布式部署，消息由Producer通过多种负载均衡模式发送到Broker集群，发送低延时，支持快速失败。
- Broker，消息中转角色，负责存储消息，转发消息。以Topic为纬度支持轻量级的队列，具有上亿级消息堆积能力，同时可严格保证消息的有序性。
- Consumer，消息消费者，负责消费消息，一般是后台系统负责异步消费。Consumer也由用户部署，支持PUSH和PULL两种消费模式，支持集群消费和广播消息，提供实时的消息订阅机制。

##### 流程：Broker在启动的时候会去向NameServer注册并且定时发送心跳 -> Producer在启动的时候会到NameServer上去拉取Topic所属的Broker具体地址，然后向具体的Broker发送消息 -> 消费者通过pull或者push拉取消息消费

### broker如何实现存储的 
- 先将数据写入缓存里提高读取速度，然后异步线程将缓存中的数据写入磁盘。通过CommitLog文件进行数据的存储，CommitLog 只有一个文件，为了方便保存和读写被切分为多个子文件，所有的子文件通过其保存的第一个和最后一个消息的物理位点进行连接。　Broker 按照时间和物理的 offset 顺序写 CommitLog 文件，每次写的时候需要加锁。
- 　每个 CommitLog 子文件的大小默认是 1GB（ 1024 * 1024 * 1024B），可以通过 mapedFileSizeCommitLog 进行配置。当一个 CommitLog 写满后，创建一个新的 CommitLog，继续上一个 CommitLog 的 Offset 写操作，直到写满换成下一个文件。所有 CommitLog 子文件之间的 Offset 是连接，所以最后一个 CommitLog 总是被写入的。

### 消息模型
- 主要分为Message、Topic、Queue、Offset以及Group这几部分。
  - topic Topic表示消息的第一级类型，,最细粒度的订阅单位，一个Group可以订阅多个Topic的消息。
  - tag Tag表示消息的第二级类型，是对topic的细化
  - Group 组，一个组可以订阅多个Topic。
  - Message Queue 消息的物理管理单位。一个Topic下可以有多个Queue，Queue的引入使得消息的存储可以分布式集群化，具有了水平扩展能力。可以认为 Message Queue 是一个长度无限的数组，Offset 就是下标。

### mq为什么很快，采用pagecache和顺序写 
- 　Page Cache：现代操作系统内核被设计为按照 Page 读取文件，每个 Page 默认为 4KB。因为程序一般符合局部性原理，所以操作系统在读取一段文件内容时，会将该段内容和附件的文件内容都读取到内核 Page 中（预读），下次读取的内容如果命中 Page Cache 就可以直接返回内容，不用再次读取磁盘。
- 顺序写，发送消息时，生产者端的消息是顺序写入CommitLog

### 如何实现消息幂等 
- 发送时重复：通过生产者生成唯一标识，比如订单号，保证消息的唯一性
- 消费时重复：消费时候可以通过唯一标识查询订单状态判断是否消费过了；增加唯一标识防止插入重复数据；引入锁，保证整个事务整体成功或失败

### 消息如何不丢失 -从生产端、broker、消费端分析
- 生产者：通过事务消息保证消息不丢失
- broker：刷盘策略改为同步
- 消费者：消费完成之后给broker ack消息，表示消费完成
 

### 事务消息如何实现 
- 首先生产者发送half消息到RocketMQ中，此时消费者是无法消费half消息的，若half消息就发送失败了，则执行相应的回滚逻辑
- half消息发送成功之后，且RocketMQ返回成功响应，则执行生产者的核心链路
- 如果生产者自己的核心链路执行失败，则回滚，并通知RocketMQ删除half消息
- 如果生产者的核心链路执行成功，则通知RocketMQ commit half消息，让消费者可以消费这条数据
- 长时间收不到生产者响应会回调生产者接口查询状态

### 延时消息如何实现
- 通过setDelayTimeLevel(2)方法可以直接实现延时消息发送

### 消息积压了怎么办
- 先定位问题，是producer太多导致的还是consumer太少还是消费速度异常
- producer限流，限制生产消息速度
- 增加consumer，增加消费速度
- 如果consumer和Queue不对等，需要增加topic，由一个consumer将旧topic中的数据迁移到新的topic中，然后由多个消费者消费
- 

## 分布式服务框架

### CAP
- 一致性，保证从哪个节点读到的都是最新的数据
- 可用性，集群下一部分节点故障，依旧可以提供服务
- 分区容错性，不同分区之间连接断开，依旧可以对外提供服务，这个是一定要保证的
- Zookeeper是CP，Eureka是AP

### Base
- Base是对CAP权衡的结果，要求达到下面3个状态
- 基本可用，允许响应时间增长一些，或者并发太大下可以服务降级，保证服务的可用性
- 软状态，指允许系统中的数据存在中间状态，并且这个状态不会影响系统的可用性，也就是不同节点之间的数据同步允许有延迟
- 最终一致性，要求可以没有强一致性，但是需要保证最终一致性

## springcloud和dubbo
- dubbo的关注点是服务的调用、服务分发、服务治理、流量监控和熔断，底层是基于netty这样的NIO框架，基于TCP协议传输的RPC框架
- springcloud关注点是整个微服务生态，包括配置中心、远程调用、网关配置、安全校验、服务容错等，服务调用是基于HTTP协议的rest请求，比RPC请求更灵活

### RPC
- 是远程调用协议，可以让两个部署在不同机器上的服务通过网络请求对方服务，而不需要去管网络协议。让远程调用像调用本地接口一样方便。
- 客户端调用>序列化>找到对方的服务地址并发送请求>反序列化>调用本地服务>返回结果

### dubbo架构核心
- Container： 服务运行容器，负责加载、运行服务提供者。必须。
- Provider： 暴露服务的服务提供方，会向注册中心注册自己提供的服务。必须。
- Consumer： 调用远程服务的服务消费方，会向注册中心订阅自己所需的服务。必须。
- Registry： 服务注册与发现的注册中心。注册中心会返回服务提供者地址列表给消费者。非必须。
- Monitor： 统计服务的调用次数和调用时间的监控中心。服务消费者和提供者会定时发送统计数据到监控中心。 非必须。

### dubbo原理
- config 配置层：Dubbo相关的配置。支持代码配置，同时也支持基于 Spring 来做配置，以 ServiceConfig, ReferenceConfig 为中心
- proxy 服务代理层：调用远程方法像调用本地的方法一样简单的一个关键，真实调用过程依赖代理类，以 ServiceProxy 为中心。
- registry 注册中心层：封装服务地址的注册与发现。
- cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心。
- monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心。
- protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心。
- exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心。
- transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心。
- serialize 数据序列化层 ：对需要在网络传输的数据进行序列化。

### dubbo spi是什么 
- SPI（Service Provider Interface） 机制被大量用在开源项目中，它可以帮助我们动态寻找服务/功能（比如负载均衡策略）的实现。
- SPI 的具体原理是这样的：我们将接口的实现类放在配置文件中，我们在程序运行过程中读取配置文件，通过反射加载实现类。这样，我们可以在运行的时候，动态替换接口的实现类。和 IoC 的解耦思想是类似的。
- Java 本身就提供了 SPI 机制的实现。不过，Dubbo 没有直接用，而是对 Java原生的 SPI机制进行了增强，以便更好满足自己的需求。
- JDK SPI：
  - JDK 标准的 SPI 会一次性加载所有的扩展实现，如果有的扩展很耗时，但也没用上，很浪费资源。所以只希望加载某个的实现，就不现实了
- DUBBO SPI：
  - 对 Dubbo 进行扩展，不需要改动 Dubbo 的源码
  - 延迟加载，可以一次只加载自己想要加载的扩展实现。
  - 增加了对扩展点 IOC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。
  - Dubbo 的扩展机制能很好的支持第三方 IoC 容器，默认支持 Spring Bean。


### dubbo协议
- dubbo支持很多协议，官方推荐使用dubbo协议
- Dubbo： 单一长连接和 NIO 异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。传输协议 TCP，异步 Hessian 序列化。Dubbo推荐使用dubbo协议。
- RMI： 采用 JDK 标准的 RMI 协议实现，传输参数和返回参数对象需要实现Serializable 接口，使用 Java 标准序列化机制，使用阻塞式短连接，传输数据包大小混合，消费者和提供者个数差不多，可传文件，传输协议 TCP。 多个短连接 TCP 协议传输，同步传输，适用常规的远程服务调用和 RMI 互操作。在依赖低版本的Common-Collections 包，Java 序列化存在安全漏洞。
- WebService：基于 WebService 的远程调用协议，集成 CXF 实现，提供和原生 WebService 的互操作。多个短连接，基于 HTTP 传输，同步传输，适用系统集成和跨语言调用。
- HTTP： 基于 Http 表单提交的远程调用协议，使用 Spring 的 HttpInvoke 实现。多个短连接，传输协议 HTTP，传入参数大小混合，提供者个数多于消费者，需要给应用程序和浏览器 JS 调用。
- Hessian：集成 Hessian 服务，基于 HTTP 通讯，采用 Servlet 暴露服务， Dubbo 内嵌 Jetty 作为服务器时默认实现，提供与 Hession 服务互操作。多个短连接，同步 HTTP 传输，Hessian 序列化，传入参数较大，提供者大于消费者，提供者压力较大，可传文件。
- Memcache：基于 Memcache实现的 RPC 协议。Redis：基于 Redis 实现的RPC协议。


### dubbo负载均衡策略
- 随机选取
- 轮询
- 最少活跃
- 一致性hash策略
  - 通过服务器ip对2的32次方取模，为什么是2的32次方，是因为IPV4的最大值是2的32次方，可以保证取模后不会重复，取模后放到由2的32次方个点组成的圆环上，比如有3个服务，就会把这3个服务对应取模之后的值放在环上，来了一个服务请求的时候，会对那个服务ip取模计算位置，然后计算这个位置后面的一个服务器是哪个，确定后就会访问这个服务器，通过这种方式达到负载均衡的效果

### dubbo遇到哪些坑 
- RPC远程调用失败：调用中的参数和实体类没有实现Serializable接口，并给serialVersionUID 赋值
- 父子类有相同的属性时属性丢失，因为获取属性时候，采用了Map去重，但是读取时，根据serializer的顺序读，对于相同字段，会读两次，父类的数据会把子类的覆盖
- 自定义异常抛出之后消费端收到的是runtimeException，因为dubbo除了特定的一些异常，都会把异常封装成RuntimeException异常返回，为了防止抛出一些消费端没有定义的异常，解决方式就是把自定义异常类和接口放在同一个包下

### 如何解决分布式事务，有哪些方案（比如（tcc、事务消息+补偿）
- 2PC
  - 2PC是通过一个全局的事务管理器也就是协调者完成，主要包括协调者和事件参与者
  - 执行步骤
    - 第一阶段是投票阶段，协调者发送prepare指令给参与者，参与者执行事务操作，但是不提交，并将结果返回给协调者
    - 第二阶段是决定阶段，协调者判断是否所有参与者都可以提交，都可以就会发送commit指令，如果有的参与者失败，发送abort指令
  - 弊端
    - 单点问题，依赖于事务管理器，出问题了系统就不能用了
    - 数据不一致，如果第二阶段只给部分参与者发送了commit指令就断了，就会导致数据不一致
    - 响应时间长，不适用与高并发
- 3PC
  - 是2PC的优化版本，主要优化了两个地方
    - 引入了超时机制，最后提交阶段如果一定时间没有收到协调者回复，进行提交操作，可以解决第三阶段协调者发了部分commit指令后挂掉导致的数据不一致性
    - 多加了一个canConmit阶段，目的是先提前确认所有参与者都可以去完成事务，防止有参与者已经挂了还要去执行事务
  - 执行步骤
    - canCommit，协调者询问参与者，是否有能力执行事务
    - preCommit，协调者发送prepare指令给参与者，参与者执行事务操作，但是不提交，并将结果返回给协调者
    - doCommit,协调者判断是否所有参与者都可以提交，都可以就会发送commit指令，如果有的参与者失败，发送abort指令
- TCC（补偿事务）
  - 针对每个操作，都会注册一个对应的确认和补偿操作，默认try成功了，confirm一定会成功
  - 执行步骤
    - try阶段，调用其他系统服务进行资源预留，这时候会提交，不会锁定资源
    - confirm阶段，确认提交，如果try成功了，就会执行confirm阶段，执行成功后的逻辑
    - concel阶段，失败之后的回滚操作，需要手动写回滚方法，因为已经提交了
  - 优势
    - 解决了单点问题，因为不需要事务协调器了，由业务发起
    - 不会锁定资源，
    - 有超时机制，超时后进入补偿操作
    - 数据一致性，因为有补偿机制，可以用代码控制一致性
  - 弊端
    - 因为confirm和concel都需要自己实现，业务代码比较复杂，而且不好复用

## 如何实现秒杀方案？

## zk和nacos实现原理，遇到的一些坑
- zk和nacos都可以用做配置中心和注册中心，zk是CP的，nacos既支持CP又支持AP
- zk实现原理
  - zk主要通过他的树形节点来实现的，当有数据变化的时候就会通知客户端数据变化。
  - ZAB协议是zk的核心，也就是消息广播和崩溃恢复
  - 消息广播：zk数据更新的时候，leader节点会将消息广播给其他flower节点，超过一半的flower节点响应就会提交更新
  - 崩溃恢复：当leader挂了，或者是超过半数的flower节点投票leader不可用，就会触发选举，这期间zk是不可用的，选举也是半数以上机制
- eureka原理
  - eureka是AP的，是去中心化的一个注册中心，每个节点都可以视作其他节点的副本，所以保证了高可用性，只要有一个节点没挂，就可以对外提供服务
  - 一定时间没有收到某个服务实例的心跳，会注销该实例，但是如果15分钟超过85%的服务都收不到心跳，会进入自我保护模式
- nacos实现原理
  - nacos的注册中心和配置中心是不同代码实现的
  - 配置中心是依赖于mysql的，当数据有更新的时候，会先修改数据库的数据，然后异步通知其他节点更新，在由服务节点更新本地缓存，最后通知客户端
  - 注册中心支持两种，持久化的和非持久化的，就是类似有CP和AP的概念
    - 持久化方式的话就是使用raft协议选举master节点，也是半数以上选举机制，类似于CP
    - 非持久化直接存储在节点的内存中，是去中心化的，类似于AP，节点采用hash分片存储注册信息，可用性高
- 遇到的坑
  - 

## 大数据量和高并发如何优化及方案-比如服务化、分库分表

## 如何限流降级-比如接入sentinel框架、常用的限流算法及详细
- sentinel是一个流量控制框架，从流量控制、熔断降级、系统负载等方面来保证系统的稳定性
- 流量控制：
  - 资源的调用关系，例如资源的调用链路，资源和资源之间的关系；
  - 运行指标，例如 QPS、线程池、系统负载等；
  - 控制的效果，例如直接限流、冷启动、排队等。
- 熔断降级
  - 原则上和hystrix是一样的，当某个资源不稳定的时候，比如timout，异常比例升高，则对这个资源进行限制，让请求快速失败，防止雪崩
  - 实现上，Hystrix 是通过线程池的方式，对资源进行了隔离，sentinel有下面两种方式
    - 通过并发线程数进行限制，对这个资源访问的线程数超过限制，直接拒绝
    - 通过响应时间对资源进行降级，当对某个资源的响应时间过长后，会拒绝后面对这个资源的访问，进行服务降级
- 常见4中限流算法
  - 计数器（固定窗口算法）
    - 在周期内访问次数达到某个值，会触发限流策略，有个弊端就是临界值，比如周期1分钟，阈值100，如果1分钟最后5秒和后一个1分钟开始5秒访问了100次，也就是10秒内访问了200次，超过了系统承受能力
  - 滑动窗口算法
    - 会将一个时间周期分为N个小周期，每次计算N个小周期的访问次数，然后每次滑动一个小周期，这样的优势是计算比较均匀，不会出现临界值的问题
  - 漏桶算法
    - 所有的访问请求都会放入漏桶，漏桶对以一定的速度释放请求，当漏桶满了就触发限流
  - 令牌桶算法
    - 会以时间周期/限流量的速度向桶中放入令牌，访问资源的请求都需要先获取令牌，获取不到了就会触发限流


## 数据库和缓存一致性如何解决，方案
- 如果不需要保证最终一致性，有几种方案
  - 先删缓存，在改数据库，如果改数据库的时候有读操作读了数据库又写了缓存，缓存的数据就是错的
  - 先改数据里，在删缓存，如果先有个读操作读了数据库，然后写线程写了数据库，又删了缓存，读线程又写了缓存，缓存数据也会错，不过这种几率很低，毕竟读效率比写快很多
- 如果需要最终一致性，有以下方案
  - 缓存延迟双删，也就是先删缓存，在写数据库，写完休眠一秒（确保读的线程已经读完并且写完缓存了），再删缓存。当然，休眠删除可能造成响应时间变长，吞吐量变高，可以选择异步删除缓存方式
  - 如果删除缓存失败了怎么办？可以用消息队列的重试机制
- 
